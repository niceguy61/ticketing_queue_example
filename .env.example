# =============================================================================
# Ticketing Queue System - Environment Configuration
# =============================================================================
# Copy this file to .env and update the values as needed
# For production, use strong passwords and secure credentials

# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================

# Environment: development, production, test
NODE_ENV=development

# Log level: error, warn, info, debug, trace
LOG_LEVEL=info

# =============================================================================
# DATABASE CONFIGURATION (PostgreSQL)
# =============================================================================

# PostgreSQL Database Name
POSTGRES_DB=ticketing

# PostgreSQL User
POSTGRES_USER=admin

# PostgreSQL Password (CHANGE IN PRODUCTION!)
POSTGRES_PASSWORD=password

# PostgreSQL Port
POSTGRES_PORT=5432

# Database Connection Pool Settings
DB_MAX_CONNECTIONS=20
DB_IDLE_TIMEOUT_MS=30000

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================

# Redis Port
REDIS_PORT=6379

# Redis Connection Settings
REDIS_MAX_RETRIES=3
REDIS_RETRY_DELAY_MS=1000

# =============================================================================
# MESSAGE QUEUE CONFIGURATION
# =============================================================================

# Queue Provider: redis, rabbitmq, sqs, kafka
# - redis: Simple, fast, good for development
# - rabbitmq: Feature-rich, good for local development
# - sqs: AWS managed, good for production
# - kafka: High throughput, good for event streaming
QUEUE_PROVIDER=redis

# --- RabbitMQ Configuration (if QUEUE_PROVIDER=rabbitmq) ---
RABBITMQ_USER=admin
RABBITMQ_PASSWORD=password
RABBITMQ_PORT=5672
RABBITMQ_MGMT_PORT=15672
# Full URL format: amqp://user:password@host:port
RABBITMQ_URL=amqp://admin:password@rabbitmq:5672

# --- AWS SQS Configuration (if QUEUE_PROVIDER=sqs) ---
AWS_REGION=us-east-1
# For LocalStack (local development), set AWS_ENDPOINT
# For real AWS, leave AWS_ENDPOINT empty
AWS_ENDPOINT=
# For LocalStack, use test credentials
# For real AWS, use IAM roles (leave empty) or real credentials
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# --- Kafka Configuration (if QUEUE_PROVIDER=kafka) ---
# Comma-separated list of broker addresses
# Docker 내부: kafka:29092, 외부(로컬 개발): localhost:9092
KAFKA_BROKERS=kafka:29092
# Client ID for Kafka producer/consumer
KAFKA_CLIENT_ID=queue-service
# Consumer group ID
KAFKA_GROUP_ID=queue-service-group
# Kafka ports (for Docker)
KAFKA_PORT=9092
KAFKA_UI_PORT=8082
ZOOKEEPER_PORT=2181

# =============================================================================
# LOCALSTACK CONFIGURATION (AWS Emulator for Local Development)
# =============================================================================

# LocalStack Port
LOCALSTACK_PORT=4566

# LocalStack Services (comma-separated)
LOCALSTACK_SERVICES=sqs,sns

# LocalStack Debug Mode (0 or 1)
LOCALSTACK_DEBUG=1

# =============================================================================
# USER SERVICE CONFIGURATION
# =============================================================================

# User Service Port
USER_SERVICE_PORT=3003

# Session Expiry (in hours)
SESSION_EXPIRY_HOURS=24

# =============================================================================
# TICKET SERVICE CONFIGURATION
# =============================================================================

# Ticket Service Port
TICKET_SERVICE_PORT=3002

# Ticket Expiry (in minutes)
TICKET_EXPIRY_MINUTES=30

# =============================================================================
# QUEUE SERVICE CONFIGURATION
# =============================================================================

# Queue Service Port
QUEUE_SERVICE_PORT=3001

# Queue Mode: simple, advanced
# - simple: Single lobby queue only
# - advanced: Lobby queue + ticket-specific queues
QUEUE_MODE=simple

# Lobby Queue Capacity (maximum number of users)
LOBBY_CAPACITY=1000

# Processing Rate (users per second)
PROCESSING_RATE=10

# CORS Origin (comma-separated or * for all)
CORS_ORIGIN=*

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

# Frontend Port
FRONTEND_PORT=80

# API Service URLs (for frontend build)
# Use localhost for local development
# Use service names (queue-service, ticket-service, user-service) for Docker
VITE_QUEUE_SERVICE_URL=http://localhost:3001
VITE_TICKET_SERVICE_URL=http://localhost:3002
VITE_USER_SERVICE_URL=http://localhost:3003

# =============================================================================
# DOCKER COMPOSE PROFILES
# =============================================================================
# Profiles allow you to selectively start services
# Usage: docker-compose --profile rabbitmq up
#
# Available profiles:
# - rabbitmq: Start RabbitMQ message queue
# - localstack: Start LocalStack AWS emulator
# - kafka: Start Kafka with Zookeeper and Kafka UI
#
# Example: Start with RabbitMQ
#   docker-compose --profile rabbitmq up
#
# Example: Start with LocalStack
#   docker-compose --profile localstack up
#
# Example: Start with Kafka
#   docker-compose --profile kafka up
#
# Example: Start with both RabbitMQ and LocalStack
#   docker-compose --profile rabbitmq --profile localstack up

# =============================================================================
# PRODUCTION DEPLOYMENT NOTES
# =============================================================================
#
# 1. Change all default passwords (POSTGRES_PASSWORD, RABBITMQ_PASSWORD)
# 2. Use strong, randomly generated passwords
# 3. For AWS deployment:
#    - Use IAM roles instead of access keys
#    - Set AWS_ENDPOINT to empty
#    - Use AWS Secrets Manager for sensitive data
# 4. Set NODE_ENV=production
# 5. Adjust capacity and rate limits based on load testing
# 6. Enable SSL/TLS for all external connections
# 7. Use environment-specific .env files (.env.production, .env.staging)
# 8. Never commit .env files to version control

# =============================================================================
# QUICK START EXAMPLES
# =============================================================================
#
# --- Local Development (Simple Mode with Redis) ---
# QUEUE_MODE=simple
# QUEUE_PROVIDER=redis
# NODE_ENV=development
#
# --- Local Development (Advanced Mode with RabbitMQ) ---
# QUEUE_MODE=advanced
# QUEUE_PROVIDER=rabbitmq
# Start with: docker-compose --profile rabbitmq up
#
# --- Local Development (with LocalStack SQS) ---
# QUEUE_PROVIDER=sqs
# AWS_ENDPOINT=http://localstack:4566
# AWS_ACCESS_KEY_ID=test
# AWS_SECRET_ACCESS_KEY=test
# Start with: docker-compose --profile localstack up
#
# --- AWS Production (with Real SQS) ---
# QUEUE_PROVIDER=sqs
# AWS_REGION=ap-northeast-2
# AWS_ENDPOINT=
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# (Use IAM roles instead of keys)
#
# --- Local Development (with Kafka) ---
# QUEUE_PROVIDER=kafka
# KAFKA_BROKERS=kafka:29092
# KAFKA_CLIENT_ID=queue-service
# KAFKA_GROUP_ID=queue-service-group
# Start with: docker-compose --profile kafka up
