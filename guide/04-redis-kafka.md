# Redis + Kafka ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°

Redis ZSETì˜ ì‹¤ì‹œê°„ ìœ„ì¹˜ ì¶”ì ê³¼ Apache Kafkaì˜ ê³ ì„±ëŠ¥ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ê²°í•©í•œ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.

## ê°œìš”

```mermaid
flowchart TB
    subgraph Clients
        C1([Web Client])
        C2([Mobile Client])
    end
    
    subgraph "ECS/EKS Services"
        QS[Queue Service<br/>ëŒ€ê¸°ì—´ ê´€ë¦¬]
        TS[Ticket Service<br/>í‹°ì¼“ ë°œê¸‰]
        US[User Service<br/>ì‚¬ìš©ì ê´€ë¦¬]
        NS[Notification Service<br/>ì•Œë¦¼ ë°œì†¡]
    end
    
    subgraph "ElastiCache (ìƒíƒœ ê´€ë¦¬)"
        Redis[(ElastiCache Redis)]
        Q1[queue:lobby ZSET]
        Q2[queue:event:* ZSET]
        Session[session:* Hash]
    end
    
    subgraph "MSK (ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°)"
        Kafka[(Amazon MSK)]
        T1[ticket-issue Topic]
        T2[ticket-issued Topic]
        T3[notification Topic]
    end
    
    subgraph "Consumer Groups"
        CG1[ticket-processor-group]
        CG2[notification-group]
    end
    
    C1 & C2 --> QS & TS & US
    
    QS --> Q1 & Q2
    TS --> Redis
    US --> Session
    
    QS -->|produce| T1
    TS -->|produce| T2
    
    T1 --> CG1 --> TS
    T2 --> CG2 --> NS
    T3 --> CG2
```

### ë‹¤ì¤‘ ì„œë¹„ìŠ¤ êµ¬ì¡°
- **Queue Service**: ElastiCache ZSET ê´€ë¦¬ + Kafka ì´ë²¤íŠ¸ ë°œí–‰
- **Ticket Service**: í‹°ì¼“ ë°œê¸‰ + ë°œê¸‰ ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
- **Consumer Groups**: í† í”½ë³„ Consumer Groupì´ ë©”ì‹œì§€ ì²˜ë¦¬
- **Notification Service**: ì•Œë¦¼ í† í”½ êµ¬ë…í•˜ì—¬ í‘¸ì‹œ/ì´ë©”ì¼ ë°œì†¡

## ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

### ëŒ€ê¸°ì—´ ì§„ì… â†’ í‹°ì¼“ ë°œê¸‰ â†’ ì•Œë¦¼ ì „ì²´ íë¦„

```mermaid
sequenceDiagram
    autonumber
    participant C as Client
    participant QS as Queue Service
    participant R as ElastiCache
    participant K as Kafka (MSK)
    participant TC as Ticket Consumer
    participant TS as Ticket Service
    participant NC as Notify Consumer
    participant NS as Notification

    rect rgb(230, 245, 255)
        Note over C,R: 1. ëŒ€ê¸°ì—´ ì§„ì… (Redis)
        C->>QS: POST /queue/join
        QS->>R: ZADD queue:lobby
        R-->>QS: OK
        QS->>R: ZRANK queue:lobby
        R-->>QS: position: 42
        QS-->>C: { position: 43 }
    end

    rect rgb(255, 245, 230)
        Note over QS,K: 2. ì°¨ë¡€ ë„ë‹¬ ì‹œ ì´ë²¤íŠ¸ ë°œí–‰
        QS->>R: ZPOPMIN queue:lobby
        R-->>QS: { userId }
        QS->>K: produce(ticket-issue, {userId})
        K-->>QS: offset: 1234
    end

    rect rgb(230, 255, 230)
        Note over K,TS: 3. Consumerê°€ í‹°ì¼“ ë°œê¸‰ ì²˜ë¦¬
        K->>TC: poll(ticket-issue)
        TC->>TS: POST /tickets/issue
        TS-->>TC: { ticketId }
        TC->>K: commit offset
    end

    rect rgb(255, 230, 245)
        Note over TS,NS: 4. í‹°ì¼“ ë°œê¸‰ ì™„ë£Œ â†’ ì•Œë¦¼ ë°œì†¡
        TS->>K: produce(ticket-issued, {userId, ticketId})
        K->>NC: poll(ticket-issued)
        NC->>NS: sendPush(userId, "í‹°ì¼“ ë°œê¸‰ ì™„ë£Œ!")
        NS-->>NC: sent
        NC->>K: commit offset
        NS-->>C: ğŸ”” í‘¸ì‹œ ì•Œë¦¼
    end
```

### íŒŒí‹°ì…˜ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬

```mermaid
sequenceDiagram
    autonumber
    participant P as Producer
    participant K as Kafka
    participant P0 as Partition 0
    participant P1 as Partition 1
    participant P2 as Partition 2
    participant C1 as Consumer 1
    participant C2 as Consumer 2
    participant C3 as Consumer 3

    Note over P,C3: key ê¸°ë°˜ íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ìˆœì„œ ë³´ì¥

    P->>K: produce(key: "event-A", msg1)
    K->>P0: append (event-A â†’ P0)
    P->>K: produce(key: "event-B", msg2)
    K->>P1: append (event-B â†’ P1)
    P->>K: produce(key: "event-A", msg3)
    K->>P0: append (ê°™ì€ key â†’ ê°™ì€ íŒŒí‹°ì…˜)

    Note over K,C3: Consumer Group ë‚´ íŒŒí‹°ì…˜ ë¶„ë°°

    par ë³‘ë ¬ ì²˜ë¦¬
        P0->>C1: poll (event-A ë©”ì‹œì§€ë“¤)
        P1->>C2: poll (event-B ë©”ì‹œì§€ë“¤)
        P2->>C3: poll (event-C ë©”ì‹œì§€ë“¤)
    end

    Note over C1: event-A ë‚´ì—ì„œëŠ” ìˆœì„œ ë³´ì¥
    C1->>K: commit offset
    C2->>K: commit offset
    C3->>K: commit offset
```

### Consumer ì¥ì•  ì‹œ ë¦¬ë°¸ëŸ°ì‹±

```mermaid
sequenceDiagram
    autonumber
    participant K as Kafka
    participant C1 as Consumer 1
    participant C2 as Consumer 2
    participant C3 as Consumer 3

    Note over K,C3: ì •ìƒ ìƒíƒœ: 3ê°œ íŒŒí‹°ì…˜, 3ê°œ Consumer

    K->>C1: P0 í• ë‹¹
    K->>C2: P1 í• ë‹¹
    K->>C3: P2 í• ë‹¹

    rect rgb(255, 230, 230)
        Note over C2: Consumer 2 ì¥ì•  ë°œìƒ
        C2--xK: âŒ heartbeat ì‹¤íŒ¨
    end

    rect rgb(255, 245, 230)
        Note over K,C3: ë¦¬ë°¸ëŸ°ì‹± íŠ¸ë¦¬ê±°
        K->>K: session.timeout ì´ˆê³¼ ê°ì§€
        K->>C1: ë¦¬ë°¸ëŸ°ì‹± ì‹œì‘
        K->>C3: ë¦¬ë°¸ëŸ°ì‹± ì‹œì‘
    end

    rect rgb(230, 255, 230)
        Note over K,C3: íŒŒí‹°ì…˜ ì¬í• ë‹¹
        K->>C1: P0, P1 í• ë‹¹
        K->>C3: P2 í• ë‹¹
        Note over C1: C1ì´ P1ë„ ì²˜ë¦¬
    end
```

## Apache Kafkaë€?

- **ë¶„ì‚° ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼**: LinkedInì—ì„œ ê°œë°œ, Apache ì¬ë‹¨ ì˜¤í”ˆì†ŒìŠ¤
- **ê³ ì„±ëŠ¥**: ì´ˆë‹¹ ìˆ˜ë°±ë§Œ ë©”ì‹œì§€ ì²˜ë¦¬ ê°€ëŠ¥
- **ë‚´êµ¬ì„±**: ë””ìŠ¤í¬ ê¸°ë°˜ ì €ì¥ìœ¼ë¡œ ë©”ì‹œì§€ ì˜ì†ì„± ë³´ì¥
- **í™•ì¥ì„±**: íŒŒí‹°ì…˜ ê¸°ë°˜ ìˆ˜í‰ í™•ì¥

## ì—­í•  ë¶„ë‹´

### ElastiCache (Redis ZSET)
| ì—­í•  | ì„¤ëª… |
|------|------|
| ğŸ“ ìœ„ì¹˜ ì¶”ì  | ì‚¬ìš©ìì˜ ì‹¤ì‹œê°„ ëŒ€ê¸° ìœ„ì¹˜ |
| ğŸ”¢ ìˆœì„œ ê´€ë¦¬ | FIFO ìˆœì„œ ë³´ì¥ |
| ğŸ” ìƒíƒœ ì¡°íšŒ | ë¹ ë¥¸ ìœ„ì¹˜/í¬ê¸° ì¡°íšŒ |
| ğŸš« ì¤‘ë³µ ë°©ì§€ | ê°™ì€ ì‚¬ìš©ì ì¤‘ë³µ ì§„ì… ì°¨ë‹¨ |

### Kafka (MSK)
| ì—­í•  | ì„¤ëª… |
|------|------|
| ğŸ“¬ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° | ëŒ€ìš©ëŸ‰ ì´ë²¤íŠ¸ ì²˜ë¦¬ |
| âš–ï¸ íŒŒí‹°ì…˜ ë³‘ë ¬ ì²˜ë¦¬ | Consumer Group ê¸°ë°˜ ë¶€í•˜ ë¶„ì‚° |
| ğŸ“š ë©”ì‹œì§€ ë³´ì¡´ | ì„¤ì •ëœ ê¸°ê°„ ë™ì•ˆ ë©”ì‹œì§€ ë³´ê´€ |
| ğŸ”„ ì¬ì²˜ë¦¬ ê°€ëŠ¥ | offset ì¡°ì •ìœ¼ë¡œ ê³¼ê±° ë©”ì‹œì§€ ì¬ì²˜ë¦¬ |

## ì¥ì 

| ì¥ì  | ì„¤ëª… |
|------|------|
| âš¡ **ì´ˆê³ ì„±ëŠ¥** | ì´ˆë‹¹ ìˆ˜ë°±ë§Œ ë©”ì‹œì§€ ì²˜ë¦¬ |
| ğŸ“š **ë©”ì‹œì§€ ë³´ì¡´** | ì„¤ì • ê¸°ê°„ ë™ì•ˆ ëª¨ë“  ë©”ì‹œì§€ ë³´ê´€ |
| ğŸ”„ **ì¬ì²˜ë¦¬ ê°€ëŠ¥** | offset ì¡°ì •ìœ¼ë¡œ ê³¼ê±° ì´ë²¤íŠ¸ ì¬ì²˜ë¦¬ |
| âš–ï¸ **ìˆ˜í‰ í™•ì¥** | íŒŒí‹°ì…˜ ì¶”ê°€ë¡œ ì²˜ë¦¬ëŸ‰ ì¦ê°€ |
| ğŸ”— **ì´ë²¤íŠ¸ ì†Œì‹±** | ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì— ì í•© |
| ğŸ“Š **ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬** | Kafka Streams, ksqlDB ì—°ë™ |

## ë‹¨ì 

| ë‹¨ì  | ì„¤ëª… |
|------|------|
| ğŸ—ï¸ **ìš´ì˜ ë³µì¡ë„** | Zookeeper/KRaft, ë¸Œë¡œì»¤ ê´€ë¦¬ |
| ğŸ“š **í•™ìŠµ ê³¡ì„ ** | íŒŒí‹°ì…˜, Consumer Group ë“± ê°œë… í•™ìŠµ |
| ğŸ’° **ì¸í”„ë¼ ë¹„ìš©** | ìµœì†Œ 3ê°œ ë¸Œë¡œì»¤ ê¶Œì¥ |
| â±ï¸ **ì§€ì—° ì‹œê°„** | RabbitMQ ëŒ€ë¹„ ì•½ê°„ ë†’ì€ ì§€ì—° |
| ğŸ”§ **ì„¤ì • ë³µì¡** | íŠœë‹ íŒŒë¼ë¯¸í„°ê°€ ë§ìŒ |

## ì‚¬ìš© ì‚¬ë¡€

### âœ… ì í•©í•œ ê²½ìš°
- ëŒ€ê·œëª¨ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
- ì´ë²¤íŠ¸ ì†Œì‹± ì•„í‚¤í…ì²˜
- ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸
- ë¡œê·¸ ìˆ˜ì§‘/ë¶„ì„
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ ë¹„ë™ê¸° í†µì‹ 
- ë©”ì‹œì§€ ì¬ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°

### âŒ ë¶€ì í•©í•œ ê²½ìš°
- ì†Œê·œëª¨ ì‹œìŠ¤í…œ (ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§)
- ë‹¨ìˆœí•œ ì‘ì—… í
- ê·¹ë„ë¡œ ë‚®ì€ ì§€ì—° ì‹œê°„ í•„ìš” (<1ms)
- ìš´ì˜ ì¸ë ¥/ê²½í—˜ ë¶€ì¡±

## Kafka í•µì‹¬ ê°œë…

### í† í”½ê³¼ íŒŒí‹°ì…˜
```
Topic: ticket-issue
â”œâ”€â”€ Partition 0: [msg1, msg4, msg7, ...]
â”œâ”€â”€ Partition 1: [msg2, msg5, msg8, ...]
â””â”€â”€ Partition 2: [msg3, msg6, msg9, ...]
```

### Consumer Group
```mermaid
flowchart LR
    subgraph Topic
        P0[Partition 0]
        P1[Partition 1]
        P2[Partition 2]
    end
    
    subgraph "Consumer Group A"
        C1[Consumer 1]
        C2[Consumer 2]
    end
    
    P0 --> C1
    P1 --> C1
    P2 --> C2
```

### Offset ê´€ë¦¬
```
Partition 0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
                          â†‘
                    committed offset
                    (Consumerê°€ ì²˜ë¦¬ ì™„ë£Œí•œ ìœ„ì¹˜)
```

## êµ¬í˜„ ì˜ˆì‹œ

### Producer (Queue Service)
```typescript
import { Kafka, Producer } from 'kafkajs';

class KafkaQueueService {
  private producer: Producer;

  async publishTicketEvent(userId: string, eventId: string): Promise<void> {
    await this.producer.send({
      topic: 'ticket-issue',
      messages: [{
        key: eventId,  // ê°™ì€ ì´ë²¤íŠ¸ëŠ” ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ
        value: JSON.stringify({
          userId,
          eventId,
          timestamp: Date.now()
        })
      }]
    });
  }
}
```

### Consumer (Worker)
```typescript
import { Kafka, Consumer, EachMessagePayload } from 'kafkajs';

class TicketConsumer {
  private consumer: Consumer;

  async start(): Promise<void> {
    await this.consumer.subscribe({ 
      topic: 'ticket-issue',
      fromBeginning: false 
    });

    await this.consumer.run({
      eachMessage: async ({ topic, partition, message }: EachMessagePayload) => {
        const data = JSON.parse(message.value!.toString());
        
        try {
          // í‹°ì¼“ ë°œê¸‰
          const ticket = await this.ticketService.issue(data.userId);
          
          // Socket.io ì•Œë¦¼
          this.io.to(data.userId).emit('ticket:issued', ticket);
          
          // ìë™ offset commit (autoCommit: true)
        } catch (error) {
          // ì—ëŸ¬ ì‹œ offset commit ì•ˆ ë¨ â†’ ì¬ì²˜ë¦¬
          throw error;
        }
      }
    });
  }
}
```

## AWS MSK vs ìì²´ ìš´ì˜

| í•­ëª© | Amazon MSK | ìì²´ ìš´ì˜ (EKS) |
|------|------------|-----------------|
| ê´€ë¦¬ | AWS ê´€ë¦¬í˜• | ì§ì ‘ ìš´ì˜ |
| ë¹„ìš© | ì‹œê°„ë‹¹ ê³¼ê¸ˆ | EC2/EKS ë¹„ìš© |
| í™•ì¥ | ì½˜ì†”ì—ì„œ ë¸Œë¡œì»¤ ì¶”ê°€ | ìˆ˜ë™ í™•ì¥ |
| ëª¨ë‹ˆí„°ë§ | CloudWatch í†µí•© | Prometheus ë“± ë³„ë„ êµ¬ì„± |
| ë²„ì „ ì—…ê·¸ë ˆì´ë“œ | AWS ì§€ì› | ì§ì ‘ ìˆ˜í–‰ |
| Zookeeper | MSKê°€ ê´€ë¦¬ | ì§ì ‘ ìš´ì˜ ë˜ëŠ” KRaft |

## í™˜ê²½ë³„ êµ¬ì„±

### ë¡œì»¬ ê°œë°œ (Docker Compose)
```yaml
# docker-compose.yml (--profile kafka)
zookeeper:
  image: confluentinc/cp-zookeeper:7.5.0
  
kafka:
  image: confluentinc/cp-kafka:7.5.0
  environment:
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092

kafka-ui:
  image: provectuslabs/kafka-ui:latest
  ports:
    - "8082:8080"
```

### AWS í”„ë¡œë•ì…˜ (MSK)
```typescript
const kafka = new Kafka({
  clientId: 'queue-service',
  brokers: [
    'b-1.msk-cluster.xxx.kafka.ap-northeast-2.amazonaws.com:9092',
    'b-2.msk-cluster.xxx.kafka.ap-northeast-2.amazonaws.com:9092',
    'b-3.msk-cluster.xxx.kafka.ap-northeast-2.amazonaws.com:9092'
  ],
  ssl: true,
  sasl: {
    mechanism: 'scram-sha-512',
    username: process.env.MSK_USERNAME!,
    password: process.env.MSK_PASSWORD!
  }
});
```

## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸

| ë©”íŠ¸ë¦­ | ì„¤ëª… | ì„ê³„ê°’ ì˜ˆì‹œ |
|--------|------|-------------|
| Consumer Lag | ì²˜ë¦¬ ì§€ì—° ë©”ì‹œì§€ ìˆ˜ | > 10,000 ê²½ê³  |
| Messages In/Out | ì´ˆë‹¹ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ | íŠ¸ë˜í”½ íŒ¨í„´ í™•ì¸ |
| Under Replicated Partitions | ë³µì œ ì§€ì—° íŒŒí‹°ì…˜ | > 0 ê²½ê³  |
| Request Latency | ìš”ì²­ ì§€ì—° ì‹œê°„ | > 100ms ê²½ê³  |
| Disk Usage | ë¸Œë¡œì»¤ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ | > 80% ê²½ê³  |

## ë‹¤ìŒ ë‹¨ê³„

ë„¤ ê°€ì§€ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•˜ê³  ìƒí™©ì— ë§ëŠ” ì„ íƒì„ í•´ë³´ì„¸ìš”.
â†’ [ì•„í‚¤í…ì²˜ ë¹„êµ ê°€ì´ë“œ](05-comparison.md)



## âš ï¸ ìš´ì˜ ë ˆë²¨ ìœ„í—˜ ìƒí™©

### 1. Consumer Lag ê¸‰ì¦

**ìƒí™©**: Consumer ì²˜ë¦¬ ì†ë„ê°€ Producer ë°œí–‰ ì†ë„ë¥¼ ë”°ë¼ê°€ì§€ ëª»í•¨

**ì¦ìƒ**:
- Consumer Lag ë©”íŠ¸ë¦­ ê¸‰ì¦
- ë©”ì‹œì§€ ì²˜ë¦¬ ì§€ì—°
- ì‚¬ìš©ì í‹°ì¼“ ë°œê¸‰ ì§€ì—°

**ì›ì¸**:
- Consumer ìˆ˜ ë¶€ì¡±
- ì²˜ë¦¬ ë¡œì§ ë³‘ëª©
- ì™¸ë¶€ ì„œë¹„ìŠ¤ ì§€ì—°
- íŒŒí‹°ì…˜ ìˆ˜ ëŒ€ë¹„ Consumer ë¶€ì¡±

**ëŒ€ì‘**:
```bash
# Consumer Lag í™•ì¸
kafka-consumer-groups.sh --bootstrap-server kafka:9092 \
  --group ticket-processor-group --describe

# íŠ¹ì • íŒŒí‹°ì…˜ lag í™•ì¸
kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list kafka:9092 --topic ticket-issue
```

**ì˜ˆë°©**:
```typescript
// Consumer ìˆ˜ ì¦ê°€ (íŒŒí‹°ì…˜ ìˆ˜ë§Œí¼)
// íŒŒí‹°ì…˜ 3ê°œ â†’ Consumer 3ê°œê¹Œì§€ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥

// ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ì¦ê°€
await consumer.run({
  eachBatch: async ({ batch, resolveOffset, heartbeat }) => {
    for (const message of batch.messages) {
      await processMessage(message);
      resolveOffset(message.offset);
      await heartbeat();
    }
  }
});
```

---

### 2. ë¦¬ë°¸ëŸ°ì‹± í­í’ (Rebalancing Storm)

**ìƒí™©**: Consumer Groupì´ ê³„ì† ë¦¬ë°¸ëŸ°ì‹±ë˜ì–´ ì²˜ë¦¬ ì¤‘ë‹¨

**ì¦ìƒ**:
- ì¦ì€ "Rebalancing" ë¡œê·¸
- ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ë‹¨/ì¬ì‹œì‘ ë°˜ë³µ
- ì¤‘ë³µ ì²˜ë¦¬ ë°œìƒ

**ì›ì¸**:
- session.timeout.ms ë„ˆë¬´ ì§§ìŒ
- heartbeat.interval.ms ì„¤ì • ë¬¸ì œ
- Consumer ì²˜ë¦¬ ì‹œê°„ì´ max.poll.interval.ms ì´ˆê³¼
- ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì •

**ëŒ€ì‘**:
```typescript
// í˜„ì¬ ë¦¬ë°¸ëŸ°ì‹± ìƒíƒœ í™•ì¸
kafka-consumer-groups.sh --bootstrap-server kafka:9092 \
  --group ticket-processor-group --describe --state
```

**ì˜ˆë°©**:
```typescript
const consumer = kafka.consumer({
  groupId: 'ticket-processor-group',
  sessionTimeout: 30000,        // 30ì´ˆ (ê¸°ë³¸ 10ì´ˆë³´ë‹¤ ì—¬ìœ ìˆê²Œ)
  heartbeatInterval: 3000,      // 3ì´ˆ
  maxPollInterval: 300000,      // 5ë¶„ (ê¸´ ì²˜ë¦¬ í—ˆìš©)
  rebalanceTimeout: 60000       // ë¦¬ë°¸ëŸ°ì‹± íƒ€ì„ì•„ì›ƒ
});
```

---

### 3. ë¸Œë¡œì»¤ ì¥ì• 

**ìƒí™©**: Kafka ë¸Œë¡œì»¤ ë…¸ë“œ ë‹¤ìš´

**ì¦ìƒ**:
- íŠ¹ì • íŒŒí‹°ì…˜ ë¦¬ë” ì—†ìŒ
- Producer/Consumer ì—°ê²° ì‹¤íŒ¨
- Under Replicated Partitions ì¦ê°€

**ì›ì¸**:
- ì„œë²„ ì¥ì• 
- ë””ìŠ¤í¬ í’€
- OOM (Out of Memory)
- ë„¤íŠ¸ì›Œí¬ ë‹¨ì ˆ

**ëŒ€ì‘**:
```bash
# í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
kafka-metadata.sh --snapshot /var/kafka-logs/__cluster_metadata-0/00000000000000000000.log --command "broker"

# íŒŒí‹°ì…˜ ë¦¬ë” í™•ì¸
kafka-topics.sh --bootstrap-server kafka:9092 \
  --topic ticket-issue --describe

# Under Replicated Partitions í™•ì¸
kafka-topics.sh --bootstrap-server kafka:9092 \
  --describe --under-replicated-partitions
```

**ì˜ˆë°©**:
```bash
# ìµœì†Œ 3ê°œ ë¸Œë¡œì»¤ êµ¬ì„±
# replication.factor=3
# min.insync.replicas=2

# í† í”½ ìƒì„± ì‹œ
kafka-topics.sh --create --topic ticket-issue \
  --partitions 6 \
  --replication-factor 3 \
  --config min.insync.replicas=2
```

---

### 4. ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

**ìƒí™©**: ë¸Œë¡œì»¤ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì„ê³„ì¹˜ ì´ˆê³¼

**ì¦ìƒ**:
- ìƒˆ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨
- ë¸Œë¡œì»¤ ë¹„ì •ìƒ ì¢…ë£Œ
- Producer ì—ëŸ¬

**ì›ì¸**:
- retention.ms/bytes ì„¤ì • ê³¼ë‹¤
- íŠ¸ë˜í”½ ê¸‰ì¦
- ë¡œê·¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë¦¬ ì§€ì—°

**ëŒ€ì‘**:
```bash
# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
df -h /var/kafka-logs

# í† í”½ë³„ ì‚¬ìš©ëŸ‰ í™•ì¸
du -sh /var/kafka-logs/*

# ê¸´ê¸‰: retention ì¤„ì´ê¸°
kafka-configs.sh --bootstrap-server kafka:9092 \
  --alter --entity-type topics --entity-name ticket-issue \
  --add-config retention.ms=3600000  # 1ì‹œê°„ìœ¼ë¡œ ì¶•ì†Œ
```

**ì˜ˆë°©**:
```bash
# ì ì ˆí•œ retention ì„¤ì •
kafka-topics.sh --create --topic ticket-issue \
  --config retention.ms=86400000 \     # 1ì¼
  --config retention.bytes=1073741824  # 1GB per partition

# ë¡œê·¸ ì••ì¶• í™œì„±í™” (í•„ìš”ì‹œ)
--config cleanup.policy=compact
```

---

### 5. ë©”ì‹œì§€ ìˆœì„œ ê¹¨ì§

**ìƒí™©**: ê°™ì€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
- ë‚˜ì¤‘ ìš”ì²­ì´ ë¨¼ì € ì²˜ë¦¬ë¨
- ë°ì´í„° ì •í•©ì„± ë¬¸ì œ
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì˜¤ë¥˜

**ì›ì¸**:
- key ì—†ì´ ë©”ì‹œì§€ ë°œí–‰ (ë¼ìš´ë“œë¡œë¹ˆ)
- ì—¬ëŸ¬ íŒŒí‹°ì…˜ì— ë¶„ì‚°
- ì¬ì‹œë„ë¡œ ì¸í•œ ìˆœì„œ ë³€ê²½

**ëŒ€ì‘**:
```typescript
// ë©”ì‹œì§€ ìˆœì„œ í™•ì¸
const admin = kafka.admin();
const offsets = await admin.fetchTopicOffsets('ticket-issue');
console.log(offsets);
```

**ì˜ˆë°©**:
```typescript
// key ê¸°ë°˜ íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ìˆœì„œ ë³´ì¥
await producer.send({
  topic: 'ticket-issue',
  messages: [{
    key: eventId,  // ê°™ì€ ì´ë²¤íŠ¸ â†’ ê°™ì€ íŒŒí‹°ì…˜ â†’ ìˆœì„œ ë³´ì¥
    value: JSON.stringify(data)
  }]
});

// idempotent producer í™œì„±í™”
const producer = kafka.producer({
  idempotent: true,
  maxInFlightRequests: 1  // ìˆœì„œ ë³´ì¥ ê°•í™”
});
```

---

### 6. ì¤‘ë³µ ë©”ì‹œì§€ ì²˜ë¦¬

**ìƒí™©**: ê°™ì€ ë©”ì‹œì§€ê°€ ì—¬ëŸ¬ ë²ˆ ì²˜ë¦¬ë¨

**ì¦ìƒ**:
- í‹°ì¼“ ì¤‘ë³µ ë°œê¸‰
- ì•Œë¦¼ ì¤‘ë³µ ë°œì†¡
- ë°ì´í„° ì¤‘ë³µ

**ì›ì¸**:
- Consumer ì¥ì•  í›„ ì¬ì‹œì‘
- ë¦¬ë°¸ëŸ°ì‹± ì¤‘ offset commit ì‹¤íŒ¨
- at-least-once íŠ¹ì„±

**ëŒ€ì‘**:
```typescript
// ì¤‘ë³µ í™•ì¸ í›„ ì²˜ë¦¬
const processMessage = async (message: KafkaMessage) => {
  const data = JSON.parse(message.value!.toString());
  const messageId = `${message.topic}-${message.partition}-${message.offset}`;
  
  // ì´ë¯¸ ì²˜ë¦¬ëœ ë©”ì‹œì§€ì¸ì§€ í™•ì¸
  const processed = await redis.get(`processed:${messageId}`);
  if (processed) {
    return; // ì¤‘ë³µ ìŠ¤í‚µ
  }
  
  await processTicket(data);
  
  // ì²˜ë¦¬ ì™„ë£Œ ë§ˆí‚¹ (TTL ì„¤ì •)
  await redis.set(`processed:${messageId}`, '1', 'EX', 86400);
};
```

**ì˜ˆë°©**:
```typescript
// ë©±ë“±ì„± ë³´ì¥
const issueTicket = async (userId: string): Promise<Ticket> => {
  // ì´ë¯¸ ë°œê¸‰ëœ í‹°ì¼“ í™•ì¸
  const existing = await db.findTicket({ userId, status: 'pending' });
  if (existing) return existing;
  
  return await db.createTicket({ userId });
};

// Exactly-once ì„¤ì • (Kafka Transactions)
const producer = kafka.producer({
  transactionalId: 'ticket-processor',
  idempotent: true
});
```

---

### 7. Zookeeper/KRaft ì¥ì• 

**ìƒí™©**: ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ ì¥ì• 

**ì¦ìƒ**:
- ë¸Œë¡œì»¤ ë¦¬ë” ì„ ì¶œ ë¶ˆê°€
- í† í”½/íŒŒí‹°ì…˜ ë©”íƒ€ë°ì´í„° ë¶ˆì¼ì¹˜
- í´ëŸ¬ìŠ¤í„° ì „ì²´ ì¥ì• 

**ì›ì¸**:
- Zookeeper ì¿¼ëŸ¼ ì†ì‹¤
- ë„¤íŠ¸ì›Œí¬ íŒŒí‹°ì…˜
- ë””ìŠ¤í¬ ì¥ì• 

**ëŒ€ì‘**:
```bash
# Zookeeper ìƒíƒœ í™•ì¸
echo stat | nc localhost 2181

# KRaft ëª¨ë“œ ìƒíƒœ í™•ì¸
kafka-metadata.sh --snapshot /var/kafka-logs/__cluster_metadata-0/00000000000000000000.log --command "quorum"
```

**ì˜ˆë°©**:
```bash
# Zookeeper 3ë…¸ë“œ ì´ìƒ êµ¬ì„±
# KRaft ëª¨ë“œ ì‚¬ìš© ê¶Œì¥ (Kafka 3.3+)

# MSK ì‚¬ìš© ì‹œ AWSê°€ ê´€ë¦¬
```

---

### 8. Redis-Kafka ë™ê¸°í™” ì‹¤íŒ¨

**ìƒí™©**: Redisì—ì„œ ì œê±°ëì§€ë§Œ Kafka ë°œí–‰ ì‹¤íŒ¨

**ì¦ìƒ**:
- ì‚¬ìš©ìê°€ ëŒ€ê¸°ì—´ì—ì„œ ì‚¬ë¼ì§
- í‹°ì¼“ ë¯¸ë°œê¸‰
- ë°ì´í„° ë¶ˆì¼ì¹˜

**ì›ì¸**:
- Kafka ë¸Œë¡œì»¤ ì—°ê²° ì‹¤íŒ¨
- ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ
- Producer ë²„í¼ í’€

**ëŒ€ì‘**:
```typescript
// ê³ ì•„ ì‚¬ìš©ì íƒì§€ ë° ë³µêµ¬
const findOrphanedUsers = async (): Promise<string[]> => {
  const removed = await redis.sMembers('queue:removed:pending');
  const processed = await db.getProcessedUsers(removed);
  return removed.filter(u => !processed.includes(u));
};
```

**ì˜ˆë°©**:
```typescript
// Transactional Outbox íŒ¨í„´
const processUser = async (userId: string): Promise<void> => {
  await db.transaction(async (tx) => {
    // 1. Outboxì— ì´ë²¤íŠ¸ ì €ì¥
    await tx.insert('outbox', {
      topic: 'ticket-issue',
      key: userId,
      payload: JSON.stringify({ userId }),
      status: 'pending'
    });
    
    // 2. Redisì—ì„œ ì œê±°
    await redis.zRem('queue:lobby', userId);
  });
  
  // 3. ë³„ë„ í”„ë¡œì„¸ìŠ¤ê°€ outbox â†’ Kafka ë°œí–‰
};

// Outbox Relay í”„ë¡œì„¸ìŠ¤
const relayOutbox = async () => {
  const pending = await db.query('SELECT * FROM outbox WHERE status = ?', ['pending']);
  for (const event of pending) {
    await producer.send({
      topic: event.topic,
      messages: [{ key: event.key, value: event.payload }]
    });
    await db.update('outbox', { status: 'sent' }, { id: event.id });
  }
};
```

---

### ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | í™•ì¸ |
|------|------|
| ìµœì†Œ 3ê°œ ë¸Œë¡œì»¤ êµ¬ì„± | â˜ |
| replication.factor >= 3 | â˜ |
| min.insync.replicas = 2 | â˜ |
| Consumer Group ëª¨ë‹ˆí„°ë§ | â˜ |
| Consumer Lag ì•ŒëŒ ì„¤ì • | â˜ |
| ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì•ŒëŒ | â˜ |
| key ê¸°ë°˜ íŒŒí‹°ì…”ë‹ | â˜ |
| ë©±ë“±ì„± ì²˜ë¦¬ êµ¬í˜„ | â˜ |
| ì ì ˆí•œ retention ì„¤ì • | â˜ |
| session.timeout íŠœë‹ | â˜ |
| Redis-Kafka ë™ê¸°í™” ë¡œì§ | â˜ |
| ì¥ì•  ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™” | â˜ |
